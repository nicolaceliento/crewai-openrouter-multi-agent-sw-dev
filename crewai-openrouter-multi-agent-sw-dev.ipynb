{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a61f97e",
   "metadata": {},
   "source": [
    "## Sistema Multi-Agente per lo Sviluppo Software con LLM\n",
    "\n",
    "Questo notebook implementa un **sistema multi-agente** basato su **CrewAI** e integrato con **OpenRouter.AI**, in cui pi√π **modelli linguistici di grandi dimensioni (LLM)** collaborano in modo coordinato, ciascuno con un **ruolo specifico** all'interno del ciclo di vita di un progetto software.  \n",
    "L‚Äôobiettivo √® simulare un team di sviluppo virtuale in grado di gestire un progetto software dall'analisi iniziale fino alla verifica finale.\n",
    "\n",
    "---\n",
    "\n",
    "### üë• Ruoli e Responsabilit√†\n",
    "\n",
    "- **Project Manager**\n",
    "- **Solution Architect**\n",
    "- **Technical Lead**\n",
    "- **Frontend Developer**\n",
    "- **Backend Developer**\n",
    "- **Database Administrator**\n",
    "- **QA & Test Engineer**\n",
    "\n",
    "---\n",
    "\n",
    "### üîÅ Flusso del Processo Collaborativo\n",
    "\n",
    "```text\n",
    "Project Manager ‚Üí Solution Architect ‚Üí Technical Lead\n",
    "                              ‚Üì\n",
    "       Frontend Dev ‚Üê‚Üí Backend Dev ‚Üê‚Üí DB Admin\n",
    "                              ‚Üì\n",
    "                     QA & Test Engineer\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üß≠ Descrizione del Processo\n",
    "\n",
    "- Il **Project Manager** riceve in input i parametri utente (`project_name`, `project_type`, `project_requirements`) e redige un documento di *Specifiche di Progetto*.\n",
    "- Il **Solution Architect** definisce l‚Äôarchitettura tecnica del sistema, selezionando i componenti principali e le linee guida progettuali.\n",
    "- Il **Technical Lead** costruisce un *piano di implementazione* articolato in un backlog di attivit√†, assegnando priorit√†, responsabili e dipendenze.\n",
    "- Gli sviluppatori **Frontend**, **Backend** e il **Database Administrator** realizzano le varie componenti applicative seguendo il piano stabilito.\n",
    "- Il **QA & Test Engineer** verifica la correttezza, la robustezza e la coerenza delle implementazioni rispetto ai requisiti iniziali e alle specifiche tecniche.\n",
    "\n",
    "I deliverables prodotti da ogni agent vengono salvati in formato MarkDown nella cartella /outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b863f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "from dotenv import load_dotenv\n",
    "from crewai import Agent, Task, Crew\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Caricamento variabili d'ambiente\n",
    "load_dotenv(\"vars.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0764e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametri del progetto\n",
    "project_name = \"ToDo list per la gestione di attivit√† personali\"\n",
    "project_type = \"Web App\"\n",
    "project_requirements = [\n",
    "    # Requisiti Funzionali\n",
    "    \"L'utente pu√≤ creare nuove attivit√† con titolo, descrizione, data di scadenza e priorit√†\",\n",
    "    \"Le attivit√† devono essere visualizzabili in una lista ordinabile per data, priorit√† o stato\",\n",
    "    \"L'utente pu√≤ modificare attivit√† esistenti (titolo, descrizione, scadenza, priorit√†)\",\n",
    "    \"L'utente pu√≤ eliminare attivit√† dalla lista\",\n",
    "    \"L'utente pu√≤ contrassegnare un'attivit√† come completata\",\n",
    "    \"√à possibile filtrare le attivit√† per stato (completate/in sospeso), priorit√† e cercarle per testo\",\n",
    "    \"Il sistema pu√≤ inviare notifiche per attivit√† prossime alla scadenza\",\n",
    "    \"Le attivit√† possono essere assegnate a categorie personalizzate o etichette (tag)\",\n",
    "    \"Il software consente di salvare e ripristinare le attivit√† (backup locale o cloud)\",\n",
    "    \"Le attivit√† si sincronizzano tra pi√π dispositivi con lo stesso account\",\n",
    "   \n",
    "    # Requisiti Non Funzionali\n",
    "    \"Interfaccia semplice, intuitiva e usabile anche da utenti non esperti\",\n",
    "    \"Tempi di risposta rapidi anche con molte attivit√†\",\n",
    "    \"Supporto per pi√π piattaforme (desktop, mobile, web)\",\n",
    "    \"Il sistema garantisce l'integrit√† e la persistenza dei dati inseriti\",\n",
    "    \"I dati dell'utente devono essere protetti, soprattutto se salvati nel cloud\",\n",
    "    \"Il software deve essere scalabile per l'aggiunta futura di nuove funzionalit√†\",\n",
    "\n",
    "    # Requisiti Tecnici\n",
    "    \"Supporto per frontend in React, Angular, Vue o Flutter\",\n",
    "    \"Utilizzo di backend in Node.js, Python (Django/Flask) o Java (Spring Boot)\",\n",
    "    \"Persistenza dati locale (SQLite) o remota tramite API REST e database relazionale\",\n",
    "    \"Architettura del software basata su MVC o MVVM\",\n",
    "    \"Integrazione con notifiche push (Firebase, OneSignal) e autenticazione (OAuth, Google Sign-In)\",\n",
    "    \"Presenza di test unitari e di integrazione per garantire la qualit√† del software\"       \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8128ce4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_agents(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = yaml.safe_load(f)\n",
    "    agents = {}\n",
    "    \n",
    "    for key, cfg in data.items():\n",
    "        # Usa il modello specificato nel YAML o gpt-3.5-turbo come default\n",
    "         # Configurazione di default per llm_config\n",
    "        default_llm_config = {\n",
    "            \"model\": \"openai/gpt-3.5-turbo\",\n",
    "            \"temperature\": 0.7,\n",
    "            \"openai_api_key\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "            \"base_url\": os.getenv(\"OPENAI_API_BASE\")\n",
    "        }\n",
    "        \n",
    "        llm_config = cfg.get(\"llm_config\", default_llm_config)\n",
    "        \n",
    "        # Creazione dell'istanza ChatOpenAI    \n",
    "        llm = ChatOpenAI(\n",
    "            openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "            base_url=os.getenv(\"OPENAI_API_BASE\"),\n",
    "            llm_config=llm_config\n",
    "        )\n",
    "        \n",
    "        agent = Agent(\n",
    "            role=cfg[\"role\"],\n",
    "            goal=cfg[\"goal\"],\n",
    "            backstory=cfg[\"backstory\"],\n",
    "            verbose=cfg.get(\"verbose\", False),\n",
    "            allow_delegation=cfg.get(\"allow_delegation\", False),\n",
    "            llm=llm\n",
    "        )\n",
    "        agents[key] = agent\n",
    "    return agents\n",
    "\n",
    "def load_tasks(path, agents_dict):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = yaml.safe_load(f)\n",
    "\n",
    "    task_objs = {}\n",
    "    for key, cfg in data.items():\n",
    "        agent = agents_dict[cfg[\"agent\"]]\n",
    "        task = Task(\n",
    "            description=cfg[\"description\"],\n",
    "            expected_output=cfg.get(\"expected_output\", \"\"),\n",
    "            agent=agent\n",
    "        )\n",
    "        # Aggiungiamo output_file come attributo custom\n",
    "        task.output_file = cfg.get(\"output_file\", f\"outputs/{key}.md\")\n",
    "        task_objs[key] = task\n",
    "\n",
    "    for key, cfg in data.items():\n",
    "        if \"context\" in cfg:\n",
    "            task_objs[key].context = [task_objs[cid] for cid in cfg[\"context\"]]\n",
    "\n",
    "    return list(task_objs.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f4874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = load_agents(\"agents.yaml\")\n",
    "tasks = load_tasks(\"tasks.yaml\", agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8691997e",
   "metadata": {},
   "outputs": [],
   "source": [
    "crew = Crew(\n",
    "    agents=list(agents.values()),\n",
    "    tasks=tasks,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e524d38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The given Python dictionary\n",
    "inputs = {\n",
    "  'project_name': project_name,\n",
    "  'project_type': project_type,\n",
    "  'project_requirements': project_requirements\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5748873f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the crew\n",
    "result = crew.kickoff(\n",
    "  inputs=inputs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b40ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_task_outputs(tasks):\n",
    "    for task in tasks:\n",
    "        output = task.output or \"\"\n",
    "        # Se il task ha attributo .output_file, salviamo\n",
    "        if hasattr(task, \"output_file\"):\n",
    "            filepath = task.output_file\n",
    "        else:\n",
    "            # Se non c'√®, proviamo da description o role\n",
    "            name = task.agent.role.lower().replace(\" \", \"_\")\n",
    "            filepath = f\"outputs/{name}_output.md\"\n",
    "        os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "        with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(output.content if hasattr(output, \"content\") else str(output))\n",
    "\n",
    "save_task_outputs(tasks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
